{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import requests\n",
    "import json\n",
    "# API Keys\n",
    "from config import api_key\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google Places Types: https://developers.google.com/places/web-service/supported_types\n",
    "\n",
    "#TODO: Can we incorporate this list into the loop so this list can change without changing the code\n",
    "types = ['bank']#, 'library', 'park', 'liquor_store', 'hospital']\n",
    "\n",
    "\n",
    "\n",
    "# Read in the Dallas County Appraisal District (DCAD) property values file\n",
    "\n",
    "file = \"dcad_combined-Copy1.csv\"\n",
    "\n",
    "#create DataFrame\n",
    "dcad_df = pd.read_csv(file, usecols=['PROPERTY_ZIPCODE', 'TOT_VAL'])\n",
    "dcad_df.head(5)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "#add column for 5 digit zipcode\n",
    "dcad_df['ZIPCODE'] = dcad_df['PROPERTY_ZIPCODE'].astype(str).str[:5]\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "#Group Property Values by Zipcode\n",
    "zip_group = dcad_df.groupby('ZIPCODE')['TOT_VAL']\n",
    "\n",
    "zip_group = zip_group.mean().to_frame('TOT_VAL')\n",
    "\n",
    "#Sort the Zipcodes by propert values so we can easily get the top/bottom\n",
    "zip_group.sort_values(by='TOT_VAL', ascending=False, inplace=True)\n",
    "\n",
    "zip_group_df = zip_group.reset_index()\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "#Add columns to DataFrame to store business data\n",
    "zip_group_df['Lat'] = \"\" \n",
    "zip_group_df[\"Lng\"] = \"\"\n",
    "zip_group_df[\"City\"] = \"\"\n",
    "zip_group_df[\"State\"] = \"\"\n",
    "zip_group_df = zip_group_df.rename(columns={\"ZIPCODE\": \"Zipcode\"})\n",
    "zip_group_df[\"MeanPropertyValue\"] = zip_group_df[\"TOT_VAL\"].map(\"${:,.0f}\".format)\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "#Preview 5 Zipcodes with highest values\n",
    "zip_group_df.head(5)\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "#Get 5 Zipcodes with lowest values\n",
    "zip_group_df.tail(5)\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "# create a params dict that will be updated with new zipcode each iteration\n",
    "params = {\"key\": api_key,\"keyword\":'bank'}\n",
    "\n",
    "# print(\"entering loop for iterrows\")\n",
    "\n",
    "# Loop through the zipcode pd's and run a lat/long search for each\n",
    "for index, row in zip_group_df.iterrows():\n",
    "    base_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "\n",
    "    zipcode = row['Zipcode']\n",
    "\n",
    "    # update address key value to zipcode\n",
    "    params['address'] = zipcode\n",
    "\n",
    "    # make request\n",
    "    zips_lat_lng = requests.get(base_url, params=params)\n",
    "    \n",
    "    # convert to json\n",
    "    zips_lat_lng = zips_lat_lng.json()\n",
    "    # print(json.dumps(zips_lat_lng, indent=4, sort_keys=True))\n",
    "    # print(len(zips_lat_lng['results']))\n",
    "    if index > 2: \n",
    "        break\n",
    "\n",
    "# print(\"finishing loop for iterrows\")\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "### base_url = \"https://maps.googleapis.com/maps/api/place/textsearch/json\"\n",
    "\n",
    "\n",
    "    # update address key value to zipcode\n",
    "### params = {\"key\": api_key,\"types\":'restaurant',\"query\" : \"75201\"}\n",
    "\n",
    "base_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "params = {\"key\": api_key,\"keyword\":'bank'}\n",
    "params['address'] = zipcode\n",
    "\n",
    "    # make request\n",
    "zips_lat_lng = requests.get(base_url, params=params)\n",
    "    \n",
    "    # convert to json\n",
    "zips_lat_lng = zips_lat_lng.json()\n",
    "# print(json.dumps(zips_lat_lng, indent=4, sort_keys=True))\n",
    "# len(zips_lat_lng)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "# print(zips_lat_lng['results'])\n",
    "\n",
    "#loop through address to find city\n",
    "for i in zips_lat_lng['results'][0]['address_components']:\n",
    "  if i['types'][0] == 'locality':\n",
    "      zip_group_df.loc[index, \"City\"] = i['long_name']\n",
    "\n",
    "#loop though address to find state\n",
    "for i in zips_lat_lng['results'][0]['address_components']:\n",
    "  if i['types'][0] == 'administrative_area_level_1':\n",
    "      zip_group_df.loc[index, \"State\"] = i['short_name']\n",
    "zip_group_df.loc[index, \"Lat\"] = zips_lat_lng[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]\n",
    "zip_group_df.loc[index, \"Lng\"] = zips_lat_lng[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]\n",
    "\n",
    "print(\"after address components filter\")\n",
    "\n",
    "# Visualize to confirm lat lng appear\n",
    "zip_group_df.head(3)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# params dictionary to update each iteration\n",
    "# def findPlaces(loc=(\"35.701474\",\"51.405288\"),radius=4000, pagetoken = None):\n",
    "#     lat, lng = loc\n",
    "#     type = \"restaurant\"\n",
    "#     url = \"https://maps.googleapis.com/maps/api/place/json?location={lat},{lng}&radius={radius}&type={type}&key={APIKEY}{pagetoken}\".format(lat = lat, lng = lng, radius = radius, type = type,APIKEY = APIKEY, pagetoken = \"&pagetoken=\"+pagetoken if pagetoken else \"\")\n",
    "#     print(url)\n",
    "#     response = requests.get(url)\n",
    "#     res = json.loads(response.text)\n",
    "#     # print(res)\n",
    "#     print(\"here results ---->>> \", len(res[\"results\"]))\n",
    "\n",
    "#     for result in res[\"results\"]:\n",
    "#         info = \";\".join(map(str,[result[\"name\"],result[\"geometry\"][\"location\"][\"lat\"],result[\"geometry\"][\"location\"][\"lng\"],result.get(\"rating\",0),result[\"place_id\"]]))\n",
    "#     print(info)\n",
    "#     pagetoken = res.get(\"next_page_token\",None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for each_type in types:\n",
    "    params = {\n",
    "        #3 mi radius. A Zipcode is not returned in the results, so we cannot \n",
    "        #match against our zipcode without doing a reverse lookup for every result\n",
    "        \"radius\": 4828,\n",
    "        \"types\": each_type,\n",
    "        \"keyword\": \"bank\",\n",
    "        \"key\": api_key\n",
    "    }\n",
    "    \n",
    "    #variables for the specific column names for the business type we are searching\n",
    "    count_column = f\"{each_type}_count\"\n",
    "    rating_column = f\"{each_type}_rating\"\n",
    "    \n",
    "    #add columns for each type we looking up\n",
    "    zip_group_df[count_column] = \"\"\n",
    "    zip_group_df[rating_column] = \"\"\n",
    "\n",
    "\n",
    "    # Use the lat/lng we recovered to search for businesses\n",
    "    for index, row in zip_group_df.iterrows():\n",
    "\n",
    "        rating_sum = 0\n",
    "        rating_count = 0\n",
    "\n",
    "        # get lat, lng from df\n",
    "        lat = row[\"Lat\"]\n",
    "        lng = row[\"Lng\"]\n",
    "\n",
    "        # change location each iteration while leaving original params in place\n",
    "        #params[\"location\"] = f\"32.8326,-96.7976\" #testing 1 lat, lng\n",
    "        params[\"location\"] = f\"{lat},{lng}\"\n",
    "\n",
    "        #Google Places Search\n",
    "        base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "\n",
    "        # make request and print url\n",
    "        search_results = requests.get(base_url, params=params)\n",
    "\n",
    "        # convert to json\n",
    "        search_results = search_results.json()\n",
    "        #print(json.dumps(search_results, indent=4, sort_keys=True))\n",
    "\n",
    "        results_list = search_results['results']\n",
    "\n",
    "        #Set the business count\n",
    "        zip_group_df.loc[index, count_column] = len(results_list)\n",
    "\n",
    "        #Loop through results list to get rating for each \n",
    "        for each_result in results_list:\n",
    "            #check for KeyError since not all business have a rating\n",
    "            try:\n",
    "                #print(f'{each_result[\"name\"]}: {each_result[\"rating\"]}')\n",
    "                rating = each_result[\"rating\"]\n",
    "                rating_count += 1\n",
    "                rating_sum += rating\n",
    "            except(KeyError):\n",
    "                next\n",
    "        #Set Rating to 0 if there are not businesses returned\n",
    "        try:\n",
    "            zip_group_df.loc[index, rating_column] = rating_sum / rating_count\n",
    "        except(ZeroDivisionError):\n",
    "            zip_group_df.loc[index, rating_column] = 0\n",
    "            \n",
    "        detail_df = pd.DataFrame.from_dict(results_list, orient='columns')\n",
    "\n",
    "        if index > 2:\n",
    "            break\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "print(\"finishing nested loop\")\n",
    "\n",
    "\n",
    "zip_group_df.sort_values('TOT_VAL').head()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# params = {pagetoken}\n",
    "\n",
    "\n",
    "\n",
    "params['radius'] = params['radius'] / 3\n",
    "\n",
    "print(\"params: \", params['radius'])\n",
    "\n",
    "apikey = params['key']\n",
    "\n",
    "total = 0\n",
    "\n",
    "def findPlaces(pagetoken = None):\n",
    "    global total\n",
    "\n",
    "    if pagetoken != None: \n",
    "        params['pagetoken'] = pagetoken\n",
    "    # print(params['key'])\n",
    "\n",
    "    response = requests.get(base_url,params=params)\n",
    "    dictionary = json.loads(response.text)\n",
    "    print(len(dictionary[\"results\"]))\n",
    "    total += len(dictionary[\"results\"])\n",
    "\n",
    "    for result in dictionary[\"results\"]:\n",
    "        # print(result)\n",
    "        info = \";\".join(map(str,[result[\"name\"],result[\"geometry\"][\"location\"][\"lat\"],result[\"geometry\"][\"location\"][\"lng\"],result.get(\"rating\",0),result[\"place_id\"]]))\n",
    "        # print(info)\n",
    "        print(result[\"name\"])\n",
    "    pagetoken = dictionary.get(\"next_page_token\",None)\n",
    "\n",
    "    print(\"here -->> \", pagetoken)\n",
    "    count = 0\n",
    "\n",
    "    if (len(dictionary[\"results\"]) < 20): \n",
    "        print(\"No more entries!\")\n",
    "        return None\n",
    "\n",
    "    # while pagetoken == None and len(dictionary[\"results\"]) == 20 and count < 5: \n",
    "    #     time.sleep(5)\n",
    "    #     response = requests.get(base_url,params=params)\n",
    "    #     dictionary = json.loads(response.text)\n",
    "    #     pagetoken = dictionary.get(\"next_page_token\",None)\n",
    "    #     print(\"try again:  -->> \", pagetoken)\n",
    "    #     count += 1\n",
    "\n",
    "    return pagetoken\n",
    "\n",
    "# In[ ]:\n",
    "# time.sleep(2)\n",
    "\n",
    "# token = findPlaces(token)\n",
    "\n",
    "\n",
    "\n",
    "token = findPlaces()\n",
    "time.sleep(5)\n",
    "\n",
    "count = 0\n",
    "\n",
    "while token:\n",
    "\n",
    "    token = findPlaces(token)\n",
    "\n",
    "    count += 1\n",
    "    if count > 5:\n",
    "        break\n",
    "    # \n",
    "    time.sleep(5)\n",
    "\n",
    "    # end of loop\n",
    "\n",
    "print(\"total entries: \", total)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
