{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#widen display #thanks Nick!\n",
    "from IPython.core.display import display, HTML, clear_output\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description:\n",
    "## Compare local property values against the availability and quality of surrounding businesses.\n",
    "\n",
    "### Team Members:\n",
    "Amy, Ebony, Jin, Michael, Syed\n",
    "\n",
    "### Datasets:\n",
    "Dallas County Appraisals, Google Maps API\n",
    "\n",
    "### Questions:\n",
    "   1.    Is there a correlation between housing prices and the commercial businesses that are available in that area? (comparing high housing price area vs low housing price)\n",
    "   2.    How does the property value compare with the availability of different types of businesses in the area?\n",
    "          -  Banks\n",
    "          -  Grocery Stores\n",
    "          -  Hospitals\n",
    "          -  Cafes (Starbucks)\n",
    "   3.     Where in the Dallas area are the highest and lowest property values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import requests\n",
    "import json\n",
    "import gmaps\n",
    "import time\n",
    "\n",
    "# API Keys\n",
    "from config import api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather and clean data from Dallas County Appraisal District (DCAD) which contains the address and value for all properties in Dallas County (~500k records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the Dallas County Appraisal District (DCAD) property values file\n",
    "file = \"Resources/dcad_combined.csv\"\n",
    "\n",
    "#create DataFrame using only the columns we need\n",
    "dcad_df = pd.read_csv(file, usecols=['PROPERTY_ZIPCODE', 'TOT_VAL'])\n",
    "dcad_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column for 5 digit zipcode\n",
    "dcad_df['ZIPCODE'] = dcad_df['PROPERTY_ZIPCODE'].astype(str).str[:5]\n",
    "dcad_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group Property Values by Zipcode\n",
    "zip_group = dcad_df.groupby('ZIPCODE')['TOT_VAL']\n",
    "zip_group.mean().head().map(\"${:,.2f}\".format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe from groupby with proprty count mean value, rename columns, and sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_group_df = dcad_df.groupby('ZIPCODE')['TOT_VAL'].agg(('count', 'mean'))\\\n",
    "                    .rename(columns={'count':'PropertyValueCount', 'mean':'MeanPropertyValue'})\\\n",
    "                    .sort_values(by='MeanPropertyValue', ascending=False)\\\n",
    "                    .reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add columns to DataFrame to store the business data we are going to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_group_df[\"MeanPropertyDollarValue\"] = zip_group_df[\"MeanPropertyValue\"].map(\"${:,.0f}\".format)\n",
    "zip_group_df['Lat'] = \"\" \n",
    "zip_group_df[\"Lng\"] = \"\"\n",
    "zip_group_df[\"City\"] = \"\"\n",
    "zip_group_df[\"State\"] = \"\"\n",
    "zip_group_df = zip_group_df.rename(columns={\"ZIPCODE\": \"Zipcode\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_group_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather data from Google Maps API about businesses by Zipcode\n",
    "1. Geocode each Zipcode from DCAD\n",
    "2. Use lat/lng to search for businesses in each Zipcode\n",
    "3. Merge with property data which will be used to create charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geocding: loop through each zipcode and update the lat/lng in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a params dict that will be updated with new zipcode each iteration\n",
    "params = {\"key\": api_key}\n",
    "\n",
    "# Loop through the zipcode pd's and run a lat/long search for each\n",
    "for index, row in zip_group_df.iterrows():\n",
    "    base_geocode_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "\n",
    "    zipcode = row['Zipcode']\n",
    "\n",
    "    # update address key value to zipcode\n",
    "    params['address'] = zipcode\n",
    "\n",
    "    # make request\n",
    "    zips_lat_lng = requests.get(base_geocode_url, params=params)\n",
    "    \n",
    "    # convert to json\n",
    "    zips_lat_lng = zips_lat_lng.json()\n",
    "    #print(json.dumps(zips_lat_lng, indent=4, sort_keys=True))\n",
    "    \n",
    "    #loop through address to find city\n",
    "    for i in zips_lat_lng['results'][0]['address_components']:\n",
    "        if i['types'][0] == 'locality':\n",
    "            zip_group_df.loc[index, \"City\"] = i['long_name']\n",
    "    \n",
    "    #loop though address to find state\n",
    "    for i in zips_lat_lng['results'][0]['address_components']:\n",
    "        if i['types'][0] == 'administrative_area_level_1':\n",
    "            zip_group_df.loc[index, \"State\"] = i['short_name']\n",
    "    \n",
    "    #Update Lat, Long in Dataframe\n",
    "    zip_group_df.loc[index, \"Lat\"] = zips_lat_lng[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]\n",
    "    zip_group_df.loc[index, \"Lng\"] = zips_lat_lng[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize to lat/lng have been populated\n",
    "zip_group_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for calling Google Places search and paging through the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPlaces(params):\n",
    "    #set global variable so name is returned\n",
    "    global next_page_token\n",
    "    global results_list\n",
    "\n",
    "    #Google Places Search\n",
    "    base_places_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "\n",
    "    response = requests.get(base_places_url, params=params)\n",
    "    \n",
    "    search_results = json.loads(response.text)\n",
    "    results_list = search_results[\"results\"]\n",
    "    \n",
    "    #Set next page token. Default is None.\n",
    "    next_page_token = search_results.get(\"next_page_token\", None)\n",
    "    \n",
    "    time.sleep(4) #add delay because it can take a moment before the the page token is actually available to make the subsequent call\n",
    "\n",
    "    return next_page_token, results_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the types of businesses to lookup:  we chose to focus on essential businesses like banks, supermarkets, hospitals and starbucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google Places Types: https://developers.google.com/places/web-service/supported_types\n",
    "\n",
    "#The types list can include multiple categories. A count and mean rating will be added to the final DataFrame for each type\n",
    "types = ['bank','supermarket','hospital', 'cafe']\n",
    "\n",
    "bank_names = ['bank', 'credit union']\n",
    "not_supermarket_names = ['dollar', 'cents', 'liquor', 'convenience']\n",
    "hospital_names = ['hospital', 'medical center', 'parkland']\n",
    "cafe_names = ['starbucks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count and summarize ratings for each business type using the lat/lng by radius using Google Places API and update our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# params dictionary to update each iteration\n",
    "for each_type in types:\n",
    "    \n",
    "    #clear console before starting a new type\n",
    "    clear_output()\n",
    "    \n",
    "    params = {\n",
    "        #3 mi radius. A Zipcode is not returned in the results, so we cannot \n",
    "        #match against our zipcode without doing a reverse lookup for every result\n",
    "        \"radius\": 4828,\n",
    "        \"types\": each_type,\n",
    "        \"key\": api_key,\n",
    "    }\n",
    "    \n",
    "    if each_type == 'cafe':\n",
    "        params[\"keyword\"] = 'starbucks' \n",
    "    else: \n",
    "        params[\"keyword\"] = None\n",
    "    \n",
    "    #variables for the specific column names for the business type we are searching\n",
    "    count_column = f\"{each_type}_count\"\n",
    "    rating_column = f\"{each_type}_rating\"\n",
    "    \n",
    "    #add columns for the business type we are looking up\n",
    "    zip_group_df[count_column] = 0\n",
    "    zip_group_df[rating_column] = 0\n",
    "\n",
    "   \n",
    "    # Use the lat/lng we recovered to search for businesses\n",
    "    for index, row in zip_group_df.iterrows():\n",
    "\n",
    "        rating_sum = 0\n",
    "        rating_count = 0\n",
    "        business_count = 0\n",
    "\n",
    "        next_page_token = \"\" #initialize the page token\n",
    "\n",
    "        # get lat, lng from df\n",
    "        lat = row[\"Lat\"]\n",
    "        lng = row[\"Lng\"]\n",
    "\n",
    "        # change location each iteration while leaving original params in place\n",
    "        #params[\"location\"] = f\"32.8326,-96.7976\" #testing 1 lat, lng\n",
    "        params[\"location\"] = f\"{lat},{lng}\"\n",
    "\n",
    "        while next_page_token != None:\n",
    "            \n",
    "            params[\"pagetoken\"] = next_page_token\n",
    "            \n",
    "            #call places function\n",
    "            findPlaces(params)\n",
    "\n",
    "            #Loop through results list to count each business and get rating for each \n",
    "            for each_result in results_list:\n",
    "                \n",
    "                #get name in lower case\n",
    "                business_name_lower = each_result[\"name\"].lower()\n",
    "\n",
    "                #check to make sure a Rating since not all business have a rating\n",
    "                if each_result.get(\"rating\") != None:\n",
    "                    \n",
    "                    #check for names and keywords based on business type to exclude businesses that are not a good match\n",
    "                    if each_type == \"bank\" and any(n in business_name_lower for n in bank_names):\n",
    "                        business_count+=1\n",
    "                        rating = each_result[\"rating\"]\n",
    "                        rating_sum += rating                        \n",
    "                    \n",
    "                    if each_type == \"hospital\" and any(n in business_name_lower for n in hospital_names):\n",
    "                        business_count+=1\n",
    "                        rating = each_result[\"rating\"]\n",
    "                        rating_sum += rating     \n",
    "                    \n",
    "                    if each_type == \"supermarket\" and not(any(n in business_name_lower for n in not_supermarket_names)):\n",
    "                        business_count+=1\n",
    "                        rating = each_result[\"rating\"]\n",
    "                        rating_sum += rating\n",
    "                        \n",
    "                    if each_type == \"cafe\" and any(n in business_name_lower for n in cafe_names):\n",
    "                        business_count+=1\n",
    "                        rating = each_result[\"rating\"]\n",
    "                        rating_sum += rating                             \n",
    "                                \n",
    "                    #for printing to console\n",
    "                    info = f'{row[\"Zipcode\"]} | {each_result[\"name\"]} | location: ({round(each_result[\"geometry\"][\"location\"][\"lat\"],2)}, {round(each_result[\"geometry\"][\"location\"][\"lng\"],2)}) | rating: {each_result.get(\"rating\",0)}'\n",
    "                    print(info)\n",
    "            \n",
    "            #Set Mean Rating to None if no businesses found\n",
    "            try:\n",
    "                mean_rating = rating_sum / business_count\n",
    "                zip_group_df.loc[index, rating_column] = mean_rating\n",
    "            except(ZeroDivisionError):\n",
    "                zip_group_df.loc[index, rating_column] = None\n",
    "                \n",
    "            #Set business count in dataframe\n",
    "            zip_group_df.loc[index, count_column] = business_count\n",
    "            \n",
    "        print(f'\\nTotal number of {each_type}s found for {row[\"Zipcode\"]}: {business_count} | rating_sum: {round(rating_sum,2)} | avg_rating: {round(mean_rating,2)}')\n",
    "        print(f'------------------------------------------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create file to reference in visualizations (2_visualize-property-values-and-businesses.ipynb) so we don't have to make api calls during presentation\n",
    "zip_group_df.to_csv('Resources/_zip_group_csv_beta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_group_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
